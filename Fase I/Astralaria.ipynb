{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minsait Land Classification\n",
    "\n",
    "Modelo de clasificación automática de suelos en base a imágenes de satélite.\n",
    "Grupo **Astralaria** del centro **Universitat Poltècnica de València** formado por **Asier Serrano Aramburu** y **Mario Campos Mocholí**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Procesamiento de los datos\n",
    "\n",
    "#### 1.1 Consideraciones previas\n",
    "Podemos observar claramente que tenemos un conjunto de muestras desbalanceado y debemos ajustarlo para que el modelo a entrenar no se especialice solo en la clase *RESIDENTIAL* e ignore las demás. En nuestro caso hemos optado por un equilibrado al por menor explicado más adelante.\n",
    "\n",
    "#### 1.2 Preprocesamiento\n",
    "Para entrenar nuestro modelo todas las variables deben ser numéricas, pero tras observar los datos descubrimos que una reducida cantidad de muestras que contienen variables alfanuméricas o simplemente vacías. Podríamos haber optado por eliminar estas muestras por considerarlas corruptas, pero tras un análisis posterior descubrimos que son muy útiles, sobre todo para la clase *AGRICULTURE* por lo que optamos por completarlas y adaptarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Diccionario para codificar los nombres de las clases\n",
    "categorical_encoder_class = {'RESIDENTIAL': 0,\n",
    "    'INDUSTRIAL': 1,\n",
    "    'PUBLIC': 2,\n",
    "    'OFFICE': 3,\n",
    "    'OTHER': 4,\n",
    "    'RETAIL': 5,\n",
    "    'AGRICULTURE': 6\n",
    "}\n",
    "\n",
    "# Diccionario para codificar las variables no numéricas\n",
    "categorical_encoder_catastral = {'A': -10,\n",
    "    'B': -20,\n",
    "    'C': -30,\n",
    "    '\"\"': 50\n",
    "}\n",
    "\n",
    "# Variable que contendrá las muestras\n",
    "data = []\n",
    "\n",
    "with open(r'Data\\Modelar_UH2020.txt') as read_file:\n",
    "    # La primera linea del documento es el nombre de las variables, no nos interesa\n",
    "    read_file.readline()\n",
    "    # Leemos línea por línea adaptando las muestras al formato deseado (codificar el valor catastral y la clase)\n",
    "    for line in read_file.readlines():\n",
    "        # Eliminamos el salto de línea final\n",
    "        line = line.replace('\\n', '')\n",
    "        # Separamos por el elemento delimitador\n",
    "        line = line.split('|')\n",
    "        if line[54] in categorical_encoder_catastral:\n",
    "            line[54] = categorical_encoder_catastral[line[54]]\n",
    "            if line[54] is 50:\n",
    "                line[53] = -1\n",
    "        line[55] = categorical_encoder_class[line[55]]\n",
    "        # No nos interesa el identificador de la muestra, lo descartamos\n",
    "        data.append(line[1:])\n",
    "\n",
    "# Finalmente convertimos las muestras preprocesadas a una matriz\n",
    "data = np.array(data).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Equilibrado\n",
    "Una vez preprocesados los datos en un formato deseable para entrenar modelos, procedemos a un equilibrado de estos al por menor. Contamos con 102892‬ muestras repartidas en 90173 de la clase *RESIDENTIAL*, 4490 de *INDUSTRIAL*, 2976 de tipo *PUBLIC*, 1828 de la clase *OFFICE*, 1332 de tipo *OTHER*, 2093 de *RETAIL* y 338 de la clase *AGRICULTURE*. Después de muchas pruebas hemos optado por añadir todas las muestras de cada clase excepto la de *RESIDENTIAL* que solo añadiremos **X**. Añadir más produce especialización hacía esa clase y empeora la precisión individual de las otras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable que contendrá las muestras separadas por clase\n",
    "data_per_class = []\n",
    "\n",
    "# Añadimos una lista vacía por clase\n",
    "for _ in range(7):         \n",
    "    data_per_class.append([])\n",
    "# Añadimos a la lista de cada clase las muestras de esta\n",
    "for sample in data:\n",
    "    data_per_class[int(sample[54])].append(sample)\n",
    "\n",
    "# Variable que contendrá los datos procesados\n",
    "data_proc = []\n",
    "\n",
    "# Muestras de la clase RESIDENTIAL\n",
    "data_proc += data_per_class[0][0:12000]\n",
    "# Muestras de las otras clases\n",
    "for i in range(6):\n",
    "    data_proc += data_per_class[i + 1]\n",
    "    \n",
    "# Volvemos a convertir los datos una vez procesados a una matriz y los mezclamos\n",
    "data_proc = np.array(data_proc)\n",
    "np.random.shuffle(data_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 División\n",
    "Finalmente separamos nuestro conjunto de muestras en dos conjuntos, uno de entrenamiento y otro de validación. El tamaño de este último vendrá dado por la variable *test_avg*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Variable en el rango (0.0 - 1.0) que indica el procentaje de muestras de validación\n",
    "test_avg = 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_proc[:, :54], data_proc[:, 54], test_size = test_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entrenamiento del modelo\n",
    "\n",
    "#### 2.1 Consideraciones previas\n",
    "Contamos con un conjunto de entrenamiento considerable donde cada muestra tiene también un número elevado de variables y ademas siete clases a predecir. Es inutil entrenar un modelo basado en un separador lineal o alguna tecnica de clustering (ya que tenemos las muestras etiquetadas). Hemos optado por realizar un modelo basado en dos submodelos y por iteraciones, es decir, cada modelo sera entrenado varias veces y obtendremos su predicción local, seleccionando como predicción final aquella que se haya predicho más veces. **NOTA: Cada apartado se debera ejecutar secuencialmente pero solo a partir del 2.6 se obtendran resultados validos\n",
    "\n",
    "#### 2.2 Entrenamiento modelo XGB\n",
    "https://xgboost.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBClassifier(max_depth=None, learning_rate=0.1, n_estimators=400, verbosity=None, objective=None, \n",
    "        booster=None, tree_method=None, n_jobs=-1, gamma=None, min_child_weight=None, max_delta_step=None, \n",
    "        subsample=None, colsample_bytree=None, colsample_bylevel=None, colsample_bynode=None, reg_alpha=None, \n",
    "        reg_lambda=None, scale_pos_weight=None, base_score=None, random_state=None)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Entrenamiento modelo RandomForest\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=400, criterion='entropy', max_depth=60, min_samples_split=5, \n",
    "        min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='log2', max_leaf_nodes=None, \n",
    "        min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=-1, \n",
    "        random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Evaluación\n",
    "En la Librería Sklearn encontramos diversas funciones útiles para evaluar nuestros sistemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[2200   22   72   22    9   15    2]\n",
      " [ 163  646   41   31    9    9    8]\n",
      " [ 185   42  309   30   42   14    3]\n",
      " [ 127   81   52  113    9    9    1]\n",
      " [  71   21   46    5  131    2    0]\n",
      " [ 199   42   35   17    8   99    1]\n",
      " [   6   12    3    3    0    1   44]]\n",
      "\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.94      0.83      2342\n",
      "         1.0       0.75      0.71      0.73       907\n",
      "         2.0       0.55      0.49      0.52       625\n",
      "         3.0       0.51      0.29      0.37       392\n",
      "         4.0       0.63      0.47      0.54       276\n",
      "         5.0       0.66      0.25      0.36       401\n",
      "         6.0       0.75      0.64      0.69        69\n",
      "\n",
      "    accuracy                           0.71      5012\n",
      "   macro avg       0.66      0.54      0.58      5012\n",
      "weighted avg       0.69      0.71      0.68      5012\n",
      "\n",
      "\n",
      "Precisión: 0.7067039106145251\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Util para observar clases con poca separación entre si\n",
    "print('Matriz de confusión:\\n{}\\n\\n'.format(confusion_matrix(y_test, y_pred)))\n",
    "# Útil para conocer la precisión de cada clase y demás estadisticas\n",
    "print('Informe de clasificación:\\n{}\\n'.format(classification_report(y_test, y_pred)))\n",
    "# Útil para conocer la precisión global del modelo\n",
    "print('Precisión: {}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Predicción \n",
    "Una vez entrenado, cada modelo predecirá cada variable a estimar y almacenara la predicción para su evaluación posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable que contendrá las muestras a predecir\n",
    "data_predict = []\n",
    "\n",
    "# Mismo procesamiento de datos que para el conjunto inicial\n",
    "with open(r'Data\\Estimar_UH2020.txt') as read_file:\n",
    "    # La primera línea del documento es el nombre de las variables, no nos interesa\n",
    "    read_file.readline()\n",
    "    # Leemos línea por línea adaptando las muestras al formato deseado (codificar el valor catastral)\n",
    "    for line in read_file.readlines():\n",
    "        line = line.replace('\\n', '')\n",
    "        line = line.split('|')\n",
    "        if line[54] in categorical_encoder_catastral:\n",
    "            line[54] = categorical_encoder_catastral[line[54]]\n",
    "            if line[54] is 50:\n",
    "                line[53] = -1\n",
    "        data_predict.append(line)\n",
    "\n",
    "# Finalmente convertimos las muestras preprocesadas a una matriz (no numérica, nos interesa el id esta vez)\n",
    "data_predict = np.array(data_predict)\n",
    "\n",
    "# Lista auxiliar que contendrá las predicciones locales de cada modelo\n",
    "predictions_aux = model.predict(data_predict[:, 1:].astype('float32'))\n",
    "\n",
    "# Variable que contendrá las predicciones globales de cada muestra\n",
    "predictions = {}\n",
    "\n",
    "# Añadimos a las predicciones globales la predicción del modelo local\n",
    "for i in range(len(data_predict)):\n",
    "    if (data_predict[i, 0] not in predictions):\n",
    "        predictions[data_predict[i, 0]] = [int(predictions_aux[i])]\n",
    "    else:\n",
    "        predictions[data_predict[i, 0]].append(int(predictions_aux[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Modelo global\n",
    "Finalmente entrenamos nuestro multi-modelo tantas veces como la variable *iterations* indique. Este apartado es la fusión de los anteriores para conseguir replicar el sistema de entrenamiento. La variable *debug_mode* indica si en cada entrenamiento, el modelo mostrara estadísticas o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento completo al 0.0%\n",
      "Entrenamiento completo al 5.0%\n",
      "Entrenamiento completo al 10.0%\n",
      "Entrenamiento completo al 15.0%\n",
      "Entrenamiento completo al 20.0%\n",
      "Entrenamiento completo al 25.0%\n",
      "Entrenamiento completo al 30.0%\n",
      "Entrenamiento completo al 35.0%\n",
      "Entrenamiento completo al 40.0%\n",
      "Entrenamiento completo al 45.0%\n",
      "Entrenamiento completo al 50.0%\n",
      "Entrenamiento completo al 55.00000000000001%\n",
      "Entrenamiento completo al 60.0%\n",
      "Entrenamiento completo al 65.0%\n",
      "Entrenamiento completo al 70.0%\n",
      "Entrenamiento completo al 75.0%\n",
      "Entrenamiento completo al 80.0%\n",
      "Entrenamiento completo al 85.0%\n",
      "Entrenamiento completo al 90.0%\n",
      "Entrenamiento completo al 95.0%\n",
      "Entrenamiento completo\n"
     ]
    }
   ],
   "source": [
    "# Número de iteraciones total por modelo\n",
    "iterations = 20\n",
    "\n",
    "# Variable anterior, inicializada de nuevo\n",
    "predictions = {}\n",
    "\n",
    "# Si True, muestra información de cada modelo local tras entrenarlo\n",
    "debug_mode = False\n",
    "\n",
    "for ite in range(iterations):\n",
    "    # Mostramos el porcentaje de entrenamiento\n",
    "    print('Entrenamiento completo al {}%'.format(ite/iterations * 100))\n",
    "    \n",
    "    np.random.shuffle(data_proc)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_proc[:, :54], data_proc[:, 54], test_size = test_avg)\n",
    "    \n",
    "    # Modelo XGB\n",
    "    model = xgb.XGBClassifier(max_depth=None, learning_rate=0.1, n_estimators=400, verbosity=None, objective=None, \n",
    "        booster=None, tree_method=None, n_jobs=-1, gamma=None, min_child_weight=None, max_delta_step=None, \n",
    "        subsample=None, colsample_bytree=None, colsample_bylevel=None, colsample_bynode=None, reg_alpha=None, \n",
    "        reg_lambda=None, scale_pos_weight=None, base_score=None, random_state=None)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    if debug_mode:\n",
    "        print('Matriz de confusión:\\n{}\\n'.format(confusion_matrix(y_test, y_pred)))\n",
    "        print('Informe de clasificación:\\n{}\\n'.format(classification_report(y_test, y_pred)))\n",
    "        \n",
    "    predictions_aux = model.predict(data_predict[:, 1:].astype('float32'))\n",
    "    for i in range(len(data_predict)):\n",
    "        if (data_predict[i, 0] not in predictions):\n",
    "            predictions[data_predict[i, 0]] = [int(predictions_aux[i])]\n",
    "        else:\n",
    "            predictions[data_predict[i, 0]].append(int(predictions_aux[i]))\n",
    "        \n",
    "    # Modelo RandomForest\n",
    "    model = RandomForestClassifier(n_estimators=400, criterion='entropy', max_depth=60, min_samples_split=5, \n",
    "        min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='log2', max_leaf_nodes=None, \n",
    "        min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=-1, \n",
    "        random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    if debug_mode:\n",
    "        print('Matriz de confusión:\\n{}\\n'.format(confusion_matrix(y_test, y_pred)))\n",
    "        print('Informe de clasificación:\\n{}\\n'.format(classification_report(y_test, y_pred)))\n",
    "        \n",
    "    predictions_aux = model.predict(data_predict[:, 1:].astype('float32'))\n",
    "    for i in range(len(data_predict)):\n",
    "        if (data_predict[i, 0] not in predictions):\n",
    "            predictions[data_predict[i, 0]] = [int(predictions_aux[i])]\n",
    "        else:\n",
    "            predictions[data_predict[i, 0]].append(int(predictions_aux[i]))\n",
    "print('Entrenamiento completo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Evaluación global\n",
    "Finalmente obtenemos la predicción final de cada muestra a predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario para decodificar el nombre de las clases\n",
    "categorical_decoder_class = {0: 'RESIDENTIAL',\n",
    "    1: 'INDUSTRIAL',\n",
    "    2: 'PUBLIC',\n",
    "    3: 'OFFICE',\n",
    "    4: 'OTHER',\n",
    "    5: 'RETAIL',\n",
    "    6: 'AGRICULTURE'}\n",
    "\n",
    "# Función que obtiene la moda de una lista\n",
    "def most_frequent(lst): \n",
    "    return max(set(lst), key = lst.count) \n",
    "\n",
    "with open(r'Minsait_Universitat Politècnica de València_Astralaria.txt', 'w') as write_file:\n",
    "    # Nombre de las variables respuesta\n",
    "    write_file.write('ID|CLASE\\n')\n",
    "    # Para cada muestra obtenemos su moda y volcamos el resultado a un fichero respuesta\n",
    "    for sample in data_predict:\n",
    "        write_file.write('{}|{}\\n'.format(sample[0], categorical_decoder_class[most_frequent(predictions[sample[0]])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Guardado del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
