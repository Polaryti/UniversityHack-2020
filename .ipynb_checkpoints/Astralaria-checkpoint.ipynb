{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minsait Land Classification\n",
    "\n",
    "Modelo de clasificación automática de suelos en base a imágenes de satélite.\n",
    "Grupo **Astralaria** del centro **Universitat Poltècnica de València** formado por **Asier Serrano Aramburu** y **Mario Campos Mocholí**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Procesamiento de los datos\n",
    "\n",
    "#### 1.1 Consideraciones previas\n",
    "Podemos observar claramente que tenemos un conjunto de muestras desbalanceado y debemos ajustarlo para que el modelo a entrenar no se especialice solo en la clase *RESIDENTIAL* e ignore las demás. En nuestro caso hemos optado por un equilibrado al por menor explicado más adelante.\n",
    "\n",
    "#### 1.2 Preprocesamiento\n",
    "Para entrenar nuestro modelo todas las variables deben ser numericas pero tras observar los datos descubrimos que una reducida cantidad de muestras que contienen variables con letras o simplemente vacias. Podriamos optar por eliminar estas muestras por considerarlas corruptas pero tras un analisis posterior descubrimos que son muy utilies, sobretodo para la clase *AGRICULTURE* por lo que optamos por modificarlas para que encaje en nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Diccionario para codificar los nombres de las clases\n",
    "categorical_encoder_class = {'RESIDENTIAL': 0,\n",
    "    'INDUSTRIAL': 1,\n",
    "    'PUBLIC': 2,\n",
    "    'OFFICE': 3,\n",
    "    'OTHER': 4,\n",
    "    'RETAIL': 5,\n",
    "    'AGRICULTURE': 6\n",
    "}\n",
    "\n",
    "# Diccionario para codificar las variables no númericas\n",
    "categorical_encoder_catastral = {'A': -10,\n",
    "    'B': -20,\n",
    "    'C': -30,\n",
    "    '\"\"': 50\n",
    "}\n",
    "\n",
    "# Variable que contendrá las muestras\n",
    "data = []\n",
    "\n",
    "with open(r'Data\\Modelar_UH2020.txt') as read_file:\n",
    "    # La primera linea del documento es el nombre de las variables, no nos interesa\n",
    "    read_file.readline()\n",
    "    # Leemos línea por línea adaptando las muestras al formato deseado\n",
    "    for line in read_file.readlines():\n",
    "        line = line.replace('\\n', '')\n",
    "        line = line.split('|')\n",
    "        if line[54] in categorical_encoder_catastral:\n",
    "            line[54] = categorical_encoder_catastral[line[54]]\n",
    "            if line[54] is 50:\n",
    "                line[53] = -1\n",
    "        line[55] = categorical_encoder_class[line[55]]\n",
    "        # No nos interesa el identificador de la muestra, lo descartamos\n",
    "        data.append(line[1:])\n",
    "\n",
    "# Finalmente convertimos las muestras preprocesadas a una matriz de números\n",
    "data = np.array(data).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Equilibrado\n",
    "Una vez preprocesados los datos en un formato deseable para entrenar modelos, procedemos a un equilibrado de estos al por menor. Contamos con 102892‬ muestras repartidas en 90173 de la clase *RESIDENTIAL*, 4490 de *INDUSTRIAL*, 2976 de tipo *PUBLIC*, 1828 de la clase *OFFICE*, 1332 de tipo *OTHER*, 2093 de *RETAIL* y 338 de la clase *AGRICULTURE*. Después de muchas pruebas hemos optado por añadir todas las muestras de cada clase excepto la de *RESIDENTIAL* que solo añadiremos X. Añadir más produce especialización hacía esa clase y empeora la precisión individual de las otras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable que contendra las muestras separadas por clase\n",
    "data_per_class = []\n",
    "\n",
    "# Añadimos una lista vacía por clase\n",
    "for _ in range(7):         \n",
    "    data_per_class.append([])\n",
    "# Añadimos a la lista de cada clase las muestras de esta\n",
    "for sample in data:\n",
    "    data_per_class[int(sample[54])].append(sample)\n",
    "\n",
    "# Variable que contendra los datos procesados\n",
    "data_proc = []\n",
    "\n",
    "# Muestras de la clase RESIDENTIAL\n",
    "data_proc += data_per_class[0][0:5000]\n",
    "# Muestras de las otras clases\n",
    "for i in range(6):\n",
    "    data_proc += data_per_class[i + 1]\n",
    "    \n",
    "# Volvemos a convertir los datos una vez procesados a una matriz y los mezclamos\n",
    "data_proc = np.array(data_proc)\n",
    "np.random.shuffle(data_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Separación\n",
    "Finalmente separamos nuestro conjunto de muestras en muestras de entrenamiento y de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Variable en el rango (0.0, 1.0) que indica el procentaje de muestras de validación\n",
    "test_avg = 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_proc[:, :54], data_proc[:, 54], test_size = test_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entrenamiento del modelo\n",
    "\n",
    "#### 2.1 Consideraciones previas\n",
    "Contamos con un conjunto de entrenamiento considerable donde cada muestra tiene también un número elevado de variables y ademas siete clases a predecir. Es inutil entrenar un modelo basado en un separador lineal o alguna tecnica de clustering (ya que tenemos las muestras etiquetadas). Hemos optado por realizar un modelo basado en dos submodelos y por iteraciones, es decir, cada modelo sera entrenado varias veces y obtendremos su predicción local, seleccionando como predicción final aquella que se haya predicho más veces. **NOTA: Cada apartado se debera ejecutar secuencialmente pero solo a partir del 2.6 se obtendran resultados validos\n",
    "\n",
    "#### 2.2 Entrenamiento modelo XGB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Entrenamiento modelo RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Evaluación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[799  40  79  35  12  42   1]\n",
      " [ 83 633  51  40   9  33   6]\n",
      " [112  59 339  63  39  18   2]\n",
      " [ 67  86  50 116   6  27   0]\n",
      " [ 34  32  47   4 135   4   1]\n",
      " [120  60  84  35  15 129   1]\n",
      " [  4   7   6   0   0   0  47]]\n",
      "\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.79      0.72      1008\n",
      "         1.0       0.69      0.74      0.71       855\n",
      "         2.0       0.52      0.54      0.53       632\n",
      "         3.0       0.40      0.33      0.36       352\n",
      "         4.0       0.62      0.53      0.57       257\n",
      "         5.0       0.51      0.29      0.37       444\n",
      "         6.0       0.81      0.73      0.77        64\n",
      "\n",
      "    accuracy                           0.61      3612\n",
      "   macro avg       0.60      0.56      0.58      3612\n",
      "weighted avg       0.60      0.61      0.60      3612\n",
      "\n",
      "\n",
      "0.6085271317829457\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Util para observar clases con poca sepración entre si\n",
    "print('Matriz de confusión:\\n{}\\n\\n'.format(confusion_matrix(y_test, y_pred)))\n",
    "# Útil para conocer la precisión de cada clase y demás estadisticas\n",
    "print('Informe de clasificación:\\n{}\\n'.format(classification_report(y_test, y_pred)))\n",
    "# Útil para conocer la precisión global del modelo\n",
    "#print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Predicción \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable que contendrá las muestras a predecir\n",
    "data_predict = []\n",
    "\n",
    "# Mismo procesamiento de datos que para el conjunto de entrenamiento\n",
    "with open(r'Data\\Estimar_UH2020.txt') as read_file:\n",
    "    # La primera linea del documento es el nombre de las variables, no nos interesa\n",
    "    read_file.readline()\n",
    "    # Leemos línea por línea adaptando las muestras al formato deseado\n",
    "    for line in read_file.readlines():\n",
    "        line = line.replace('\\n', '')\n",
    "        line = line.split('|')\n",
    "        if line[54] in categorical_encoder_catastral:\n",
    "            line[54] = categorical_encoder_catastral[line[54]]\n",
    "            if line[54] is 50:\n",
    "                line[53] = -1\n",
    "        data_predict.append(line)\n",
    "\n",
    "# Finalmente convertimos las muestras preprocesadas a una matriz\n",
    "data_predict = np.array(data_predict)\n",
    "\n",
    "# Lista auxiliar que contendra las predicciones locales de cada módelo\n",
    "predictions_aux = model.predict(data_predict[:, 1:].astype('float32'))\n",
    "\n",
    "# Variable que contendra para cada muestra a predecir una lista con cada clase predicha\n",
    "predictions = {}\n",
    "\n",
    "# Añadimos a las predicciones globales la predicción del módelo local\n",
    "for i in range(len(data_predict)):\n",
    "    if (data_predict[i, 0] not in predictions):\n",
    "        predictions[data_predict[i, 0]] = [int(predictions_aux[i])]\n",
    "    else:\n",
    "        predictions[data_predict[i, 0]].append(int(predictions_aux[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Predicción global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento al 0.0%\n",
      "Entrenamiento al 25.0%\n",
      "Entrenamiento al 50.0%\n",
      "Entrenamiento al 75.0%\n"
     ]
    }
   ],
   "source": [
    "# Número de iteraciones total por módelo\n",
    "iterations = 4\n",
    "\n",
    "# Variable anterior, inicializada de nuevo\n",
    "predictions = {}\n",
    "\n",
    "# Muestra información de cada modelo local tras entrenarlo\n",
    "debug_mode = True\n",
    "\n",
    "for ite in range(iterations):\n",
    "    print('Entrenamiento al {}%'.format(ite/iterations * 100))\n",
    "    np.random.shuffle(data_proc)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_proc[:, :54], data_proc[:, 54], test_size = test_avg)\n",
    "    \n",
    "    model = xgb.XGBClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    if debug_mode:\n",
    "        print('Matriz de confusión:\\n{}\\n\\n'.format(confusion_matrix(y_test, y_pred)))\n",
    "        print('Informe de clasificación:\\n{}\\n'.format(classification_report(y_test, y_pred)))\n",
    "    \n",
    "    for i in range(len(data_predict)):\n",
    "        if (data_predict[i, 0] not in predictions):\n",
    "            predictions[data_predict[i, 0]] = [int(predictions_aux[i])]\n",
    "        else:\n",
    "            predictions[data_predict[i, 0]].append(int(predictions_aux[i]))\n",
    "        \n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    if debug_mode:\n",
    "        print('Matriz de confusión:\\n{}\\n\\n'.format(confusion_matrix(y_test, y_pred)))\n",
    "        print('Informe de clasificación:\\n{}\\n'.format(classification_report(y_test, y_pred)))\n",
    "    \n",
    "    for i in range(len(data_predict)):\n",
    "        if (data_predict[i, 0] not in predictions):\n",
    "            predictions[data_predict[i, 0]] = [int(predictions_aux[i])]\n",
    "        else:\n",
    "            predictions[data_predict[i, 0]].append(int(predictions_aux[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Evaluación global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_decoder_class = {0: 'RESIDENTIAL',\n",
    "    1: 'INDUSTRIAL',\n",
    "    2: 'PUBLIC',\n",
    "    3: 'OFFICE',\n",
    "    4: 'OTHER',\n",
    "    5: 'RETAIL',\n",
    "    6: 'AGRICULTURE'}\n",
    "\n",
    "def most_frequent(lst): \n",
    "    return max(set(lst), key = lst.count) \n",
    "\n",
    "with open(r'Minsait_Universitat Politècnica de València_Astralaria.txt', 'w') as write_file:\n",
    "    write_file.write('ID|CLASE\\n')\n",
    "    for sample in data_predict:\n",
    "        write_file.write('{}|{}\\n'.format(sample[0], categorical_decoder_class[most_frequent(predictions[line[0]])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
